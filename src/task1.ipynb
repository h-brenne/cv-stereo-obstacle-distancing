{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_disparity_matrix(imgL, imgR,min_disp, max_disp, disp_size, window_radius):\n",
    "    num_disp = max_disp-min_disp\n",
    "    h, w = imgL.shape\n",
    "    \n",
    "    #The cropped center area we are interested in\n",
    "    croph = [(h-disp_size)//2,(h+disp_size)//2]\n",
    "    cropw = [(w-disp_size)//2,(w+disp_size)//2]\n",
    "\n",
    "    \n",
    "\n",
    "    ref_img_cropped = imgL[croph[0]:croph[1],cropw[0]:cropw[1]]\n",
    "\n",
    "    #Simple sum kernel for our filter\n",
    "    kernel = np.ones([window_radius, window_radius])\n",
    "\n",
    "    #C(y,x,d) is the 3D volume containing the cost of a disparity at pixel x,y in the reference\n",
    "    C = np.zeros(\n",
    "        [disp_size, disp_size, max_disp])\n",
    "\n",
    "    for d in range(min_disp, max_disp):\n",
    "        # Shift image d pixels horizontally\n",
    "        translation_matrix = np.float32([[1, 0, d], [0, 1, 0]])\n",
    "        shifted_image = cv2.warpAffine(\n",
    "            imgR, translation_matrix,\n",
    "            (imgR.shape[1], imgR.shape[0]))\n",
    "        shifted_image_cropped = shifted_image[croph[0]:croph[1],cropw[0]:cropw[1]]\n",
    "        # Absolute difference\n",
    "        AD = abs(np.float32(ref_img_cropped) - np.float32(shifted_image_cropped))\n",
    "        # Calculate SAD.\n",
    "        C[:, :, d] = cv2.filter2D(AD, -1, kernel)\n",
    "    #Add min_disp as the index is shifted\n",
    "    disparity = min_disp + np.argmin(C[:,:,min_disp:max_disp], axis=2)\n",
    "    return disparity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance_from_disparity(main_disp, f, b):\n",
    "    distance = (f*b)/(main_disp*1000)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_disparity_matrix_dynamic_range(imgL, imgR,min_disp, max_disp, disp_size, window_radius, main_disp):\n",
    "    num_disp = max_disp-min_disp\n",
    "    h, w = imgL.shape\n",
    "    \n",
    "    #Use the previous main_disp to offset disparity search around the main disparity\n",
    "    disp_offset = int(main_disp - max_disp//2)\n",
    "    if(disp_offset>0):\n",
    "        max_disp += disp_offset\n",
    "        min_disp += disp_offset\n",
    "    print(disp_offset)\n",
    "\n",
    "    #The cropped center area we are interested in\n",
    "    croph = [(h-disp_size)//2,(h+disp_size)//2]\n",
    "    cropw = [(w-disp_size)//2,(w+disp_size)//2]\n",
    "\n",
    "    ref_img_cropped = imgL[croph[0]:croph[1],cropw[0]:cropw[1]]\n",
    "\n",
    "    #Simple sum kernel for our filter\n",
    "    kernel = np.ones([window_radius, window_radius])\n",
    "\n",
    "    #C(y,x,d) is the 3D volume containing the cost of a disparity at pixel x,y in the reference\n",
    "    C = np.zeros(\n",
    "        [disp_size, disp_size, max_disp])\n",
    "\n",
    "    for d in range(min_disp, max_disp):\n",
    "        # Shift image d pixels horizontally\n",
    "        translation_matrix = np.float32([[1, 0, d], [0, 1, 0]])\n",
    "        shifted_image = cv2.warpAffine(\n",
    "            imgR, translation_matrix,\n",
    "            (imgR.shape[1], imgR.shape[0]))\n",
    "        shifted_image_cropped = shifted_image[croph[0]:croph[1],cropw[0]:cropw[1]]\n",
    "        # Absolute difference\n",
    "        AD = abs(np.float32(ref_img_cropped) - np.float32(shifted_image_cropped))\n",
    "        # Calculate SAD.\n",
    "        C[:, :, d] = cv2.filter2D(AD, -1, kernel)\n",
    "    #Add min_disp as the index is shifted\n",
    "    disparity = min_disp + np.argmin(C[:,:,min_disp:max_disp], axis=2)\n",
    "    return disparity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "\n",
    "#Stereo cameras\n",
    "focal_length = 567.2 #pixels\n",
    "baseline = 92.226 #mm\n",
    "\n",
    "#Stereo matching algorithm\n",
    "min_disp=0\n",
    "max_disp=128\n",
    "\n",
    "num_disp = max_disp-min_disp\n",
    "disparity_area_size = 100\n",
    "window_radius = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS:  8.171252678745374\n",
      "Distance to obstacle(m):  2.6475514953360904\n",
      "FPS:  7.847653545782145\n",
      "Distance to obstacle(m):  2.6329728048320122\n",
      "FPS:  8.768714224190196\n",
      "Distance to obstacle(m):  2.616039487700102\n",
      "FPS:  6.894512076849992\n",
      "Distance to obstacle(m):  2.656411533500574\n",
      "FPS:  8.7131737211114\n",
      "Distance to obstacle(m):  2.603669644768081\n",
      "FPS:  8.823704888028695\n",
      "Distance to obstacle(m):  2.651160963347389\n",
      "FPS:  7.368912610749681\n",
      "Distance to obstacle(m):  2.653500958719273\n",
      "FPS:  8.961460394241493\n",
      "Distance to obstacle(m):  2.6438983897217145\n",
      "FPS:  8.922171712766886\n",
      "Distance to obstacle(m):  2.6250583217077996\n",
      "FPS:  8.770914626750814\n",
      "Distance to obstacle(m):  2.571441987130645\n",
      "FPS:  8.550189480808315\n",
      "Distance to obstacle(m):  2.641415229246617\n",
      "FPS:  6.70566134867711\n",
      "Distance to obstacle(m):  2.6570996845650194\n",
      "FPS:  8.855748746371074\n",
      "Distance to obstacle(m):  2.632416310632709\n",
      "FPS:  8.189073046157331\n",
      "Distance to obstacle(m):  2.608590509245407\n",
      "FPS:  6.47679932796882\n",
      "Distance to obstacle(m):  2.5926877806524518\n",
      "FPS:  8.545869082862842\n",
      "Distance to obstacle(m):  2.5550512958277567\n",
      "FPS:  8.692894063809591\n",
      "Distance to obstacle(m):  2.5441160232279905\n",
      "FPS:  8.643380277046214\n",
      "Distance to obstacle(m):  2.512866210951574\n"
     ]
    }
   ],
   "source": [
    "vidL = cv2.VideoCapture('../data/robotL.avi')\n",
    "vidR = cv2.VideoCapture('../data/robotR.avi')\n",
    "if (vidL.isOpened()==False or vidR.isOpened()==False):\n",
    "  print(\"Error opening video\")\n",
    "\n",
    "# Read until video is completed\n",
    "while(vidL.isOpened()):\n",
    "      # Capture frame-by-frame\n",
    "      retL, frameL = vidL.read()\n",
    "      retR, frameR = vidR.read()\n",
    "      if retL == True and retR == True:\n",
    "        frameL_greyscale=cv2.cvtColor(frameL, cv2.COLOR_BGR2GRAY)\n",
    "        frameR_greyscale=cv2.cvtColor(frameR, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "    \n",
    "        start = time.time()\n",
    "        \n",
    "        disparity = calculate_disparity_matrix(frameL_greyscale, frameR_greyscale,min_disp, max_disp, disparity_area_size, window_radius)\n",
    "        main_disp = np.mean(disparity)\n",
    "        \n",
    "        distance = get_distance_from_disparity(main_disp, focal_length, baseline)\n",
    "        print(\"FPS: \", 1/(time.time()-start))\n",
    "        print(\"Distance to obstacle(m): \", distance)\n",
    "\t\t    \n",
    "        # Scale disparity values for visualization \n",
    "        disparity_visual = np.uint8(disparity * 255 / num_disp)\n",
    "          \n",
    "        # Show frames\n",
    "        cv2.imshow('Image', frameL)\n",
    "        cv2.imshow('Disparity', disparity_visual)\n",
    "        # Press Q on keyboard to  exit\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "      # Break the loop\n",
    "      else: \n",
    "          break\n",
    "\n",
    "# When everything done, release the video capture object\n",
    "vidL.release()\n",
    "vidR.release()\n",
    "# Closes all the frames\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MainWindow():\n",
    "    def __init__(self, window):\n",
    "        self.use_dynamic_disparity_range = False\n",
    "        self.calculate_checkerboard = True\n",
    "        self.main_disp = max_disp//2\n",
    "\n",
    "        self.window = window\n",
    "        self.vidL = cv2.VideoCapture('../data/robotL.avi')\n",
    "        self.vidR = cv2.VideoCapture('../data/robotR.avi')\n",
    "        if (self.vidL.isOpened()==False or self.vidR.isOpened()==False):\n",
    "            print(\"Error opening video\")\n",
    "\n",
    "        self.width = 800\n",
    "        self.height = 600\n",
    "        self.interval = 1 # Interval in ms to get the latest frame\n",
    "\n",
    "        self.distance_widget = tk.Label(root, text=\"Distance: 0\", width=100)\n",
    "        self.distance_widget.config(font=(\"Courier\", 20))\n",
    "        self.fps_widget = tk.Label(root, text=\"FPS: 0\", width=100)\n",
    "        self.fps_widget.config(font=(\"Courier\", 20))\n",
    "\n",
    "        # Create canvas for gui\n",
    "        self.canvas = tk.Canvas(self.window, width=self.width, height=self.height)\n",
    "        self.canvas.grid(row=0, column=0)\n",
    "        # Update gui\n",
    "        self.update_gui()\n",
    "    def update_gui(self):\n",
    "\n",
    "        # Capture frame-by-frame\n",
    "        retL, frameL = self.vidL.read()\n",
    "        retR, frameR = self.vidR.read()\n",
    "        if retL == True and retR == True:\n",
    "            frameL_greyscale=cv2.cvtColor(frameL, cv2.COLOR_BGR2GRAY)\n",
    "            frameR_greyscale=cv2.cvtColor(frameR, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "        \n",
    "            start = time.time()\n",
    "            \n",
    "            if(self.use_dynamic_disparity_range):\n",
    "                disparity = calculate_disparity_matrix_dynamic_range(frameL_greyscale, frameR_greyscale,min_disp, max_disp, \n",
    "                disparity_area_size, window_radius, self.main_disp)\n",
    "            else:\n",
    "                disparity = calculate_disparity_matrix(frameL_greyscale, frameR_greyscale,min_disp, max_disp, \n",
    "                disparity_area_size, window_radius)\n",
    "            \n",
    "            self.main_disp = np.mean(disparity)\n",
    "            \n",
    "            distance = get_distance_from_disparity(self.main_disp, focal_length, baseline)\n",
    "            fps = 1/(time.time()-start)\n",
    "            #print(\"FPS: \", 1/(time.time()-start))\n",
    "                \n",
    "            # Scale disparity values for visualization \n",
    "            disparity_visual = np.uint8(disparity * 128 / num_disp)\n",
    "            disp_heatmap = cv2.applyColorMap(disparity_visual, cv2.COLORMAP_JET)\n",
    "    \n",
    "            blue,green,red = cv2.split(frameL)\n",
    "            self.image_rgb = cv2.merge((red,green,blue))\n",
    "            self.image_rgb = Image.fromarray(self.image_rgb)\n",
    "            self.image_rgb = ImageTk.PhotoImage(image=self.image_rgb, master=root)\n",
    "\n",
    "           # Update image\n",
    "            self.canvas.create_image(0, 0, anchor=tk.NW, image=self.image_rgb)\n",
    "\n",
    "            blue,green,red = cv2.split(disp_heatmap)\n",
    "            self.image_disp = cv2.merge((red,green,blue))\n",
    "            self.image_disp = Image.fromarray(self.image_disp)\n",
    "            self.image_disp = ImageTk.PhotoImage(image=self.image_disp, master=root)\n",
    "            \n",
    "            self.canvas.create_image(680, 250, anchor=tk.NW, image=self.image_disp)\n",
    "            if(distance<0.8):\n",
    "                self.distance_widget[\"text\"] = \"ALARM! Distance to obstacle: \"+str(round(distance,2)) + \"m\"\n",
    "                self.distance_widget.config(fg=\"red\")\n",
    "            else:\n",
    "                self.distance_widget[\"text\"] = \"Distance to obstacle: \"+str(round(distance,2)) + \"m\"\n",
    "                self.distance_widget.config(fg=\"black\")\n",
    "            self.distance_widget.grid()\n",
    "\n",
    "            self.fps_widget[\"text\"] = \"FPS: \" + str(round(fps))\n",
    "            self.fps_widget.grid()\n",
    "            # Repeat every 'interval' ms\n",
    "            self.window.after(self.interval, self.update_gui)\n",
    "            \n",
    "\n",
    "        # Break the loop\n",
    "        else:             \n",
    "            # When everything done, release the video capture object\n",
    "            vidL.release()\n",
    "            vidR.release()\n",
    "            # Closes all the frames\n",
    "            cv2.destroyAllWindows()\n",
    "            quit()\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    MainWindow(root)\n",
    "    root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
